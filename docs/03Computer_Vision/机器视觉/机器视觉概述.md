---
title: 机器视觉概述
article: true
date: 2023-03-31
category:
  - 计算机视觉
tag:
  - 算法
  - 双目视觉
  - 机器视觉
order: 
icon: 🧑
---

::: tip
机器视觉概述
:::

### 硬件环境的搭建

-   **相机**
    
    相机的主要参数：分辨率、像素尺寸、帧率、像素深度、数字接口
    
    相机的种类：面阵相机和线阵相机、CMOS和CCD、黑白相机和彩色相机
    
    相机的接口：GigE接口（网口）、USB3.0、Camera Link、Fireware
    
    相机的选型：面阵相机和线阵相机
    
-   **图像采集卡**
    
    根据支持的接口、支持的分辨率等
    
-   **镜头**
    
    **接口：**C、F、CS、S
    
    **最大靶面尺寸：**芯片尺寸
    
    **物距和焦距：**
    
    **光圈：**光圈越大，进光越多
    
    **分辨率和成像质量：**分辨率越高成像越清晰
    
    **镜头倍率与视场范围：**
    
    -   **选型步骤**
        
        （1）确定相机连接的镜头接口类型，如C口或者F口，这个接口决定了镜头的接口。
        
        （2）确定镜头的最大靶面尺寸和相机匹配。
        
        （3）确定焦距。首先测量工作距离和目标物体大小，得到图像的宽或者高度；然后确定相机的安装位置，从相机的拍摄角度推测视角，最后根据几何关系计算相机焦距。
        
        （4）根据现场拍摄要求，考虑光圈、价格等其它因素。
        

### 图像的预处理

**图像的变换和校正：**二维图像的平移、旋转和缩放、图像的仿射变换、投影变换

**感兴趣区域ROI:**加快处理速度、创建形状模板

**图像增强：**直方图均衡、增强对比度、处理失焦图像

**图像的平滑和去噪：**均值滤波、中值滤波、高斯滤波

**光照不均匀：**分离RGB通道、直方图均衡、合成RGB图像

### 图像分割

**阈值处理：**全局阈值、自动全局阈分割、基于直方图阈值分割、局部阈值分割

**区域生长法：**regiongrowing算子、regiongrowing_mean算子

**分水岭算法：**

### 颜色和纹理

1、**图像的颜色：**色彩空间（RGB\HSV(色调、饱和度、纯度)\HSI(色调、饱和度、亮度)）、Bayer图像、颜色空间的转换

2、**利用颜色信息提取背景相似字符区域**

3、**纹理分析：**纹理滤波器、纺织物折痕检测

### 图像的形态学处理

**1、腐蚀：**自定义结构（圆形或者矩阵）在二值图像上进行滑动操作，二值图像对应像素点与结构元素的像素点取交集，可以收缩二值图像，用于消除边缘和噪点，使得边缘变得平滑

**2、膨胀：**二值图像对应像素点与结构元素的像素点取并集，可以扩大二值图像，填补图空隙，使得边缘变得平滑

**3、开运算：**先腐蚀后膨胀，通过腐蚀去掉小的非关键区，或者把离得很近的区域分开，在通过膨胀把过度腐蚀的区域填充。可以去除一下孤立的、细小的点，平滑毛糙的边缘线，同时区域面积也不会有明显改变

**4、闭运算：**先膨胀后腐蚀，可以把看起来很接近的区域连成一体。

**5、顶帽：**原图减去开运算结果。开运算可以移除局部像素，如去除毛边、断开相邻边缘。顶帽是用来崎岖提取这部分的。

**6、底帽：**原图减去闭运算结果。闭运算可以填补局部空隙，如空洞、使得分离的边缘连接，底帽运算就是用来提取这部分信息的。

### 特征提取

-   **1、区域形态特征：**区域面积和中心点
    
    **获取区域面积、中心**
    
    输入图像-> 灰度图像->选取ROI->阈值处理，提取深色部分->开运算去除噪点->将不相连部分分割成独立部分->获取不相连区域数量->计算各区域面积、中心点
    
    **获取封闭（孔洞）区域面积** 输入图像-> 灰度图像->选取ROI->阈值处理，提取背景区域->计算面积
    
    **根据特征值选择区域**
    
    输入图像-> 灰度图像->选取ROI->阈值处理->分割不相连区域->select_shape算子
    
    **根据特种值创建区域**
    
    输入图像-> 灰度图像->选取ROI->阈值处理->分割不相连区域->inner_circle算子
    

**2、基于灰度值的特征：**区域最大最小灰度值、灰度的平均值和偏差、灰度区域的面积和中心

-   **3、基于图像纹理特征：**灰度共生矩阵
    
    图像的纹理特征一般包括图像的质量、相关性、局部均匀性、对比度等等。 灰度共生矩阵可以反映成对的像素点之间的共生关系，可以计算灰度值特征。
    

### 边缘检测

-   **1、像素级边缘化提取一般流程**
    
    输入图像->选取ROI->图像滤波->提取边缘 ->边缘处理（生成轮廓、合并非连续边缘、分离背景）
    
-   **2、经典的边缘检测算子：**Sobel算子、Laplace算子、Canny算子
    
    **Sobel算子：**一阶导数算子，使用卷积核对每个像素进行卷积处理，采用合适的举止提取边缘。采用两个卷积核，分别计算x和y方向的导数，结合两个导数求出近似梯度。
    
    **特点:**sobel算子在检测边缘的同时尽量减少了噪声的影响，比较容易实现。它对像素位置的影响进行了加权，所以效果比较好，是比较常用的边缘检测方法。
    
    **Laplace算子：**二阶导数算子。在图像边缘区域，像素值发生较大变化，对像素求导会产生极大值，二阶导数为0，进行检测图像边缘。
    
    **特点：**Laplace算子是一种各向同性算子，比较适用于只关心边缘位置而不考虑其它周围像素灰度查的情况。Lapalce算子对孤立像素的响应要比对边缘或线的响应更加的强烈，因此只适用于无噪声图像。在存在噪声的情况下，使用Laplace算子进行边缘检测之前需要进行低通滤波处理。
    
    **Canny算子：**基本思想是寻找梯度的局部最大值。首先使用高斯平滑滤波器卷积降噪，在用一堆卷积阵列计算边缘梯度和方向，然后用非极大值抑制移除非边缘线条，最后用滞后阈值（高阈值和低阈值）检测并连接边缘。
    
    **特点：**是一种比较完善的边缘检测算法，但是存在一点不足，为了得到较好的边缘检测结果，通常需要用比较大的滤波尺度，这样容易损失一些细节。
    
-   **3、亚像素边缘提取**
    
-   **4、轮廓处理**
    
    轮廓处理：轮廓分割、轮廓筛选、轮廓连接、轮廓拟合
    

### 模板匹配

-   **1、模板匹配的种类：**基于灰度值的模板匹配、基于相关性、基于形状、基于组件、基于形变、基于描述符、基于点特征
    
    ![IMG_20221018_160957.jpg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b7a0d59b-782c-467e-b71c-7cfdec4fb74f/IMG_20221018_160957.jpg)
    
-   **2、图像金字塔：**加速模板匹配方法
    

### 图像分类

-   **1、分类器种类：** 
1、基于神经网络，特别是多层感知器MLP分类器 2、支持向量机SVM分类器 3、基于高斯混合模型GMM分类器 4、KNN分类器
    
-   **2、图像分类一般流程**
    
    (1)准备一组已知属于同一类别的样本对象，从每个样本对象中提取一组特征，存储在一个特征向量中
    
    (2)创建分类器
    
    (3)用样本的特征向量训练一个分类器。在训练过程中，用分类器计算出属于某个类别的边界条件。
    
    (4)对目标对象进行检测，获取待检测对象的特征向量。
    
    (5)分类器根据训练得到的类别的边界条件判断检测对象的特征属于哪个分类。
    
    (6)清除分类器
    
-   **3、光学字符识别OCR**
    
    离线训练步骤：一般是指字符的训练过程
    
    （1）读取样本图像，并对样本中已知的字符进行区域分割，分割单位是单个字符的包围区域。
    
    （2）将分割出的区域和对应的字符名称存储在训练文件中。
    
    （3）检查训练文件中的对应关系，即图像和字符的名称一一对应。
    
    （4）训练分类器。
    
    （5）保存分类器
    
    （6）清楚分类器
    
    在线检测步骤：指的是对字符进行检测
    
    （1）读取分类器
    
    （2）对待检测的字符进行区域分割，提取出独立的字符区域
    
    （3）使用分类器对字符区域进行分类
    
    （4）清除分类器
    

### 数字图像处理

**图像的预处理：**图像滤波、二值化、边缘提取

**图像分割：**

**数学工具：**傅里叶变换、离散余弦变换、小波变换、形态学处理

**图像的特征提取：**特征提取算法、主成分分析（PCA）、SIFT特征点、SURF特征点

### 相机成像

**射影几何和几何变换：**空间的几何变换、三维到二维投影

**成像的模型：**线性模型、非线性模型

**图像的亮度：**亮度模型、传感器、颜色模型（RGB、HSI）

**数字相机和光源：**光源、镜头、相机接口

### 相机标定与三维重建

**刚体变化的准则**：**左乘**表示依据**当前坐标系**进行变换。

**相机标定的意义：**获取像素坐标与世界坐标之间的对应关系。

**相机内参：**相机的焦距、畸变系数、中心坐标、焦距与像素单元的比值

**相机外参：**相机坐标系相对于世界坐标系的旋转矩阵和平移矩阵

**标定方法：**Matlab标定工具箱、Halcon工具箱、C++/python程序标定

**立体图像校正：**使得两张图中对应的特征点处于同一水平线上

**立体匹配：**找到左视图中的特征点，并且在对应的右视图中搜索改点，从而获得该点对应的坐标和灰度

**激光三角法测量（sheet of light）：**用特定的光源投射到物体表面，由摄像头采集图像，根据物体的光信号变化情况，确定物体的深度等位置信息。

DFF方法：使用不同焦距下拍摄的图像来重建3D表面信息。

### **机器学习中的深度学习**

-   **1、Halcon通用深度学习流程**
    
    （1）准备网络和数据：
    
    第一步：获取神经网络，可以是预先训练好的，也可以重新创建。
    
    第二步：明确网络需求。建立网络时需要明确该网络要解决的问题，根据问题的类型旋转解决的法方法。例如，如果要做分类检测，要明确有哪些分类，每个类的样本分别是什么，这些会反映到训练的数据集上，其中的图片应该能够反映各个分类样本的真实图像。再比如，如果要做物体检测，那么数据集中还需要包含标记信息。
    
    第三步：数据预处理。深度学习网络会对输入图像有一些要求，比如图像的尺寸，灰度值的范围等。
    
    第四步：数据集分割。一般分为训练集，验证集和测试集，供不同的学习阶段使用。
    
    （2）训练网络并评估训练过程
    
    第一步：设置合适训练需求的网格参数
    
    第二步：对数据进行增强和扩充
    
    第三步：开始训练并对训练过程进行评估
    
    （3）应用网络与评估网络
    
    在测试数据集上对网络进行评估。
    
    （4）实际检测
    
    将新的图像输入网络进行预测。在进行预测之前，也需要根据网络的需要对图像进行预处理。
    
-  ** 2、数据**
    
    如果数据集的图像数量比较少，也可以适当做一些数据增强。这部分可以理解为将现有的图像做一些微笑的变换，如旋转、平移、裁剪，甚至增加噪声，使之成为新的图像，然后加入训练集。另外，应当选择内容有代表性的图像假如数据集，而不要选”完美“的图像。
    
-   **3、网络与训练过程**
    
    输入图像，经过多层网络和计算和推理，输出预测结果
    
    每一层网络用于完成特定的任务，用于接收输入图像，根据特定的算法完成某种转换，并提取目标的某种特征，然后将返回的结果作为下一层的网络的输入。
    
    要训练某个任务，还需要添加损失函数。损失函数用于衡量网络的预测值和真实值的差异状况。可以调整和优化网络的各种参数，如滤波器的权重等，以使损失函数的值最小化，这样也可以提高网络的性能。在实际的网络中，这种优化操作是通过计算梯度和更新不同层的权重来实现的，不断使用训练数据集重复迭代，实现网络的优化。
    
-  ** 4、随机梯度下降**
    
    在训练数据集中，随机取出一部分数据集对网络进行训练，这样能加快每次学习的速度，并以此对滤波器的权重进行更新。
    
    随机梯度下降法的目的在于找到一个网络权重值，使得损失函数值最小。将一部分训练数据输入网络，计算损失函数，然后采用随机梯度下降法更新一次权重，如此循环迭代。每次将一部分样本数据输入网络，直到所有的训练样本都处理完毕，然后重新开始读取随机样本进行处理。
    
    训练的终止条件可以有多种，如达到设定的最大迭代次数，或者损失函数小于特定的值。可以在权重更新后进行判断，也可以在更新多次之后判断。如果前后两次计算出的权重向量的绝对误差足够小，则终止迭代。
    
    除了网络自身的参数，如权重等会影响训练过程之外，另外一些参数也会影响训练过程，这些称为超参数。他们是在训练开始就设定的值，并不会在训练过程中进行优化，如学习率，batchsize。
    
-   **5、迁移学习**
    
    从一个训练集上训练好的网络迁移到目标数据集上上。在训练中，可以在网络的第一层检测低层级特征，如边缘和形状等。在后续层提取更复杂的特征，同时特征图尺寸也更小。
    
-  ** 6、设置训练参数：超参数**
    
    超参数是一种人为设置的参数，不会在训练过程中学习得到 ，也不会随着网络的优化而调整，但是仍可以根据训练的效果设置一定的更改策略，明确在训练过程中如何去修改这些参数。
    
    网络优化的方式，是通过比较预测结果与实际图像分类之间的偏差，得到一个损失函数。然后通过不断调整网络每层的滤波器的权重，使得损失函数值达到最小。
    
    batch表示将训练集图像在细分为若干个子集，可以理解我一批图像。这批图像的数量称为batch_size，即一次迭代中同时处理的图像数量。迭代的次数称为Epochs，它决定了算法在训练集上循环迭代的次数，可以理解为一个周期，相当于全部样本完成一次训练。由于数据集是有限的，很可能在神经网络中将所有数据训练一遍还不够，有时需要将整个训练数据集在同样的网络中经过多次传递，因此可能会有多个epoch。
    
    如果batch_size太小，训练速度比较慢；太大则会加快训练速度，但是会导致内存占用比较高。
    
    每次计算完损失梯度后，为了优化网络，可以更新滤波器的权重。在更新的过程中，有两个重要的超参数，学习率和动量。同时，为了防止网络过拟合，可以对模型使用正则化。
    
    学习率：用于调整损失函数梯度下降过程中的步长。
    
    动量：用于明确前一次更新的影响因子。简单来说，在更新损失函数参数的时候，仍然需要参考上一更新的步骤。
    
    正则化参数：防止神经网络过拟合，如果该参数太小，模型可能会过拟合，如果太大，模型可能会欠拟合。
    
-   **7、验证训练结果**
    
    1、训练集中的验证：为了验证网络的表现情况，可以观察不同的样本对训练过程影响。
    
    2、欠拟合和过拟合
    
    欠拟合常常是由于训练样本不足等原因，导致模型在训练集上的误差比较大，这种情况常出现在刚开始训练网络时，也很容易被发现，需要调整训练的样本或者增加特征维度。
    
    过拟合是由于模型过度学习了训练样本，导致泛化能力变差，以至于在新的样本上表现欠佳。过度学习有可能学习过多的特征，甚至可能把样本图像的噪声等细节也当成特征。过拟合在测试集上的表现是，一开始模型的错误率不断下降，到了某个临界点后，错误率又开始上升。
    
    3、混淆矩阵
    
    （1）真阳性（TP）：属于某类，并且判断为某类
    
    （2）假阳性（FP）：不属于某类，但是预测为某类
    
    （3）真阴性（TN）：不属于某类，也没有被预测为某类
    
    （4）假阴性（FN）：属于某类，预测为不属于某类
    
-  ** 8、评估分类检测结果**
    
    （1）混淆矩阵：会给出真正例（TP）、假正例（FP）、真反例（TN）、假反例（FN）。根据4种结果可以计算精度和召回率
    
    （2）精度：指所有被识别为正样本的图像中，识别正确的比例：精度=TP/（TP+FP）
    
    （3）召回率：被正确识别出来的正样本数占据占据全部正样本的比例：=TP/（TP+FN）
    
    （4）F-Scores：精度和召回率的平衡
    
    F-Scores=2*（精度*召回率）/（精度+召回率）
        ||实际|||		
		|预测	|一类|	二类	|三类|
		|一类	|7|	2|	0|
		|二类	|2	|5	|2|
		|三类	|1	|3	|8|
    
    真正例TP:7，假正例FP：2，假反例FN：3，真反例：18.
    
    **精度**=7/(7+2)=0.778
    
    **召回率**=7/（7+3）=0.7
    
    **F-Score**=2*(0.778*0.7)/(0.7+0.778)
    
    如果一个分类器具有高精度，低召回率，那么该分类器可能识别了很少的正样本，但是这些正样本的正确率很高。如果该分类器具有低精度，高召回率，那么该分类器能识别出大部分的正样本，但是这些正样本的结果中也有可能包含了误识别的负样本。比较理想的结果是高精度高召回率。
    
-   **9、物体检测**
    
    比分类更加的复杂，它包含了两个任务，一是检测的目标是什么，二是目标的位置在哪里。
    
    实际的检测中，会给出一组制定的分类，模型会在这些分类的范围内进行分类对比，并输出目标属于每个类别的置信分数。检测结果会用矩形框在图中绘制出目标所在是区域。这些矩形的边与水平或垂直方向平行，并且与物体的边界相切。如果矩形框存在遮挡关系，还需要做一些排序和筛选。
    
    **评价指标：**
    
    1、平均精度均值：
    
    预测精度=图中某类别正确的预测数量/图中实际包含该类的目标数量
    
    对于某一类别，可以计算每张图中的预测精度，对所有图像的预测精度再取平均值
    
    平均预测精度=所有类别的平均精度之和/类别的数量
    
    影响因素：
    
    （1）训练集数据不够，导致预测性能不佳
    
    （2）数据存在多变性，可能导致某些类别的的精度较高，某些较低
    
    （3）训练数据质量不高，数据分布不均匀
    
    （4）图像标注信息不准确
    
    **2、交并比**
    
    预测的包围框与真实目标的边界包围框的重合比例
    
-   10、语义分割
    
    对图像中每一个像素都分配一个给定的分类，用于实现对图像的高层次理解。
    
    对输入的图像的每个像素用不同颜色标记其所属的不同分类，因此输出的图像和输入的图像的尺寸是完全一致的。
    
    为了降低图像中的特征维度，可以使用编码器解码器结构。编码器用于降低输入图像的空间维度，如在图像分类中进行图像局部特征的粗略提取，也可以理解为卷积或者下采样，结果就是图像的宽度高度都变小了。而解码器类似于反卷积或者上采样，用于恢复目标的细节和空间维度，将图像扩充至原来的大小，再将每一个点与所属的分类关联起来。
    

### 机器视觉实例分析

-   1、布料表面划痕
    
    输入图像→对输入图像进行傅里叶变换→创建高斯滤波器→高斯滤波→傅里叶逆变换→形态学处理→提取划痕
    
-   2、布料表面破洞
    
    输入图像→对输入图像进行傅里叶变换→创建高斯滤波器→高斯滤波→傅里叶逆变换→形态学处理、阈值处理→提取瑕疵→筛选瑕疵
    
-   3、周期纹理缺陷
    
    输入图像→增强图像对比度→对输入图像进行傅里叶变换→创建正弦带通滤波器滤波→傅里叶逆变换→纹理滤波器,放大差异→阈值处理→缺陷结果
    
-   4、周期纹理的污染区域
    
    输入图像→对输入图像进行傅里叶变换→创建两个不同参数的高斯滤波器→高斯滤波得到两张图像→二者相减，使得特定频率成分保留→阈值处理→傅里叶逆变换→缺陷结果
    
-   5、指针检测
    
    采集图像→图像对齐→创建形状模板→基于形状特征进行模板匹配
    
    如果参考图像和检测图像对比出现较大的位移或者画面抖动，那么对应的ROI会有较大的差异。在匹配之前需要先进行**图像对齐**。
    
    1、首先，在参考图像中选择一块ROI,该区域可以指定，也可以通过形态学处理获得。
    
    2、获取ROI后，提取区域中心目标，根据ROI创建形状模板。
    
    3、在待对齐的图像上通过模板匹配获取该ROI，同时也可以得到仿射变换参数。
    
    4、根据匹配获得的参数和模板原始参数，构建仿射变换矩阵
    
    5、对检测图像进行仿射变换，实现与参考图像的对齐
    
    创建形状模板，要确定模板的参数如金字塔层级、对比度。
    
    基于形状的模板匹配：输入的主要参数是模板的旋转角度、匹配的最小分值、匹配结果的数量、金字塔层级等，输出的参数包括指针位置、旋转的角度、匹配得分。
    
    匹配成功后，如果要将结果显示出来，还需要对模板图像进行仿射变换。仿射的参数从模板匹配的结果中获得，如坐标和旋转角度。通过仿射变换，将形状轮廓显示在匹配到的指针区域。
    
-   6、指针的识别
    
    首先在原图像中选择一块多边形区域，使之包围指针部分，将该区域分割出来，作为形状模板。
    
    确定形状模板的金字塔层级数和对比度参数
    
    创建形状模板，并检查创建的形状模板轮廓是否理想。
    
    读取检测图像并进行模板匹配，从图像中获得指针形状的位置坐标和旋转角度。
    
    该旋转角度和指针的旋转角度有关，用于后续计算指针的数值。
    
-   7、字符识别
    
    字符包括仪表盘中的汉字、数字、字母、特殊符号。识别过程分两步，用字符图像离线训练OCR分类器，
    
    然后使用OCR分类器进行识别。
    
    训练过程：使用阈值分割字符区域→将字符集加入训练集→创建分类器→训练
    
    （1）采集图像，将带训练的字符区域作为ROI提取出来
    
    （2）声明训练文件，将字符图像中的字符逐一添加到训练文件中
    
    （3）训练，可以使用SVM或者MLP训练
    
    在线检测：读取分类器→读取图片→分割单个字符→分类→ 输出识别的字符结果。
    
    （1）采集图片，分割ROI并找到待检测的字符区域
    
    （2）从系统中读取OCR文本识别分类器，根据给定区域的字符和OCR分类器的灰度图像值，位每个字符计算出最匹配的类别。
    
    （3）把识别出的字符变成数组，存入结果数组，得到每个字符区域的数字。
    
-   8、印刷完整性检测
    
    首先用比较理想的完整性印刷图像作为参考图像，使用形态学算法从中提取出完整图案的形状区域作为ROI，并将其从原图中裁剪出来，根据形状创建一个形状匹配模板。
    
    然后使用若干张完整图像进行形状模板匹配，目的是将ROI对齐。用对齐后的图像训练差异模板，得到一个完整图案形状的差异模型。
    
    在实际检测时，首先从拍摄到检测图像中提取ROI，然后进行形状模板匹配。通过匹配得到对齐的参数，在应用仿射变换与差异模型的图像对齐。对齐后从图像中提取ROI，并于差异图像对比，得到检测结果。
    

### 相机的标定

**相机标定的基础：**空间坐标系、空间坐标变换

**相机标定的方法：**Tsai相机标定、张正友标定

**相机标定软件实现：**Opencv棋盘格标定、Maltba棋盘格标定

**圆形标定方法：**单相机标定、立体相机标定

**机器人手眼标定：**机械臂坐标系、手眼标定

### **Shape from X**

**光度立体：**观察视角相同，在不同光照条件下采集图像恢复物体表面朝向

**从阴影恢复形状（SFS）：**建立亮度约束条件

**从运动求取结构（SFM）：**光流和运动场、多视图求取结构

**从纹理恢复形状：**利用纹理基元尺寸、基元形状、基元之间空间变化关系

### 双目立体视觉

**双目立体视觉原理：**测深原理、极限约束

**双目立体视觉系统：**平行光轴结构、精度分析

**双目标定和立体匹配：**双目立体视觉坐标系、双目立体视觉标定方法、双目立体视觉中对应点匹配

### 结构光三维视觉

**条纹投影结构光三维形貌测量：**傅里叶变换法、相位法

**条纹投影轮廓术：**DLP技术

**条纹相位提取方法：**傅里叶变换法、二维连续小波变换法、BEMD法

**条纹投影三维测量：**线激光三维测量、激光三角法测量原理

### 深度相机

**三维测量原理：**飞行时间法、结构光原理

**深度相机：**Kinect、Inter RealSense、MESA SR4000

**基于Kinect的SLAM：**RGB-D视觉SLAM算法流程、前端算法、后端算法

### 机器学习基础

**数学知识：矩阵运算**（基本运算、多元函数求导、泰勒级数、奇异值分解、最小二乘、线性相关）、**优化方法**（拉格朗日乘子、梯度下降）、**概率论**（条件概率、最大似然估计）

**机器学习的主要方法：**人工神经网络、支持向量机（SVM）、K-means聚类、集成学习（Bagging、Boosting）、深度学习和深度神经网络

### 机器学习在机器视觉的应用

**在超分辨率重建的应用：**SRCNN超分辨率重建

**在图像去噪中的应用：**DnCNN图像去噪

**在目标跟踪中的应用：**基于CNN的ECO、C-COT算法

**在三维重建中的应用：卷积神经网络用于**双目立体视觉的图像匹配、**基于EPINET深度神经网络**的光场成像和重建

**在模式识别中的应用：LeNet5**手写数字识别、基于Tensorflow的**交通标志识别**、基于深度学习框架MatConvNet**图像识别**（MNIST、CIFAR-10）、基于深度学习框架MatConvNet图像语义分割(**R-CNN**、Fast R-CNN)