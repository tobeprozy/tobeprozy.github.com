const e=JSON.parse('{"key":"v-09974639","path":"/soph%E5%BC%80%E5%8F%91/mlib/mlib.html","title":"概念","lang":"zh-CN","frontmatter":{"description":"概念 算能也对外开源了其自研的 TPU 编译工具— TPU-MLIR（Multi-Level Intermediate Representation）。TPU-MLIR 是一款主打 AI 芯片的 TPU 编译器开源工程。工程提供了完整的工具链，将预先训练好的各类框架下的神经网络，在其中进行转化，最终转化为能在 TPU 中高效运算的 二进制文件bmodel，以实现更高效的推理。 优势 TPU-MLIR已经支持TFLite以及onnx格式，这两种格式的模型可以直接转化为TPU可用的bmodel。如果不是这两种格式呢？实际上onnx提供了一套转换工具，可以将现在市面上主流深度学习框架编写的模型转为onnx格式，然后就能继续转为bmodel了","head":[["meta",{"property":"og:url","content":"https://tobeprozy.github.io/soph%E5%BC%80%E5%8F%91/mlib/mlib.html"}],["meta",{"property":"og:site_name","content":"南叔先生-开源笔记"}],["meta",{"property":"og:title","content":"概念"}],["meta",{"property":"og:description","content":"概念 算能也对外开源了其自研的 TPU 编译工具— TPU-MLIR（Multi-Level Intermediate Representation）。TPU-MLIR 是一款主打 AI 芯片的 TPU 编译器开源工程。工程提供了完整的工具链，将预先训练好的各类框架下的神经网络，在其中进行转化，最终转化为能在 TPU 中高效运算的 二进制文件bmodel，以实现更高效的推理。 优势 TPU-MLIR已经支持TFLite以及onnx格式，这两种格式的模型可以直接转化为TPU可用的bmodel。如果不是这两种格式呢？实际上onnx提供了一套转换工具，可以将现在市面上主流深度学习框架编写的模型转为onnx格式，然后就能继续转为bmodel了"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-04-26T10:25:41.000Z"}],["meta",{"property":"article:modified_time","content":"2023-04-26T10:25:41.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"概念\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-04-26T10:25:41.000Z\\",\\"author\\":[]}"]]},"headers":[],"git":{"createdTime":1682504741000,"updatedTime":1682504741000,"contributors":[{"name":"tobeprozy","email":"904762096@qq.com","commits":1}]},"readingTime":{"minutes":0.67,"words":201},"filePathRelative":"soph开发/mlib/mlib.md","localizedDate":"2023年4月26日","excerpt":"<h1> 概念</h1>\\n<p>算能也对外开源了其自研的 TPU 编译工具— TPU-MLIR（Multi-Level Intermediate Representation）。TPU-MLIR 是一款主打 AI 芯片的 TPU 编译器开源工程。工程提供了完整的工具链，将预先训练好的各类框架下的神经网络，在其中进行转化，最终转化为能在 TPU 中高效运算的 二进制文件bmodel，以实现更高效的推理。</p>\\n<h1> 优势</h1>\\n<p>TPU-MLIR已经支持TFLite以及onnx格式，这两种格式的模型可以直接转化为TPU可用的bmodel。如果不是这两种格式呢？实际上onnx提供了一套转换工具，可以将现在市面上主流深度学习框架编写的模型转为onnx格式，然后就能继续转为bmodel了</p>","autoDesc":true}');export{e as data};
