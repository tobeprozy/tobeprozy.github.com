import{_ as e,Y as o,Z as c,$ as n,a0 as s,a1 as t,a2 as p,D as u}from"./framework-d651fda7.js";const l={},i=n("p",null,"下面是一个简单的CNN的结构图，让我们来写代码实现它吧。",-1),r=n("p",null,"![[photo/1.png]]",-1),k=n("p",null,[s("上面的结构可以简化为:"),n("br"),s(" Convolutional layer->ReLU->Max Pooling->Flatten->Fully Connected layer ->ReLU-> Fully Connected")],-1),d={href:"https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fbigfishtwo%2FNeuralNetwork-python",target:"_blank",rel:"noopener noreferrer"},m=n("br",null,null,-1),v=p(`<h1 id="_1-relu" tabindex="-1"><a class="header-anchor" href="#_1-relu" aria-hidden="true">#</a> 1. ReLU</h1><p>ReLU是一个非线性的激活函数，前向传播的公式<img src="https://math.jianshu.com/math?formula=f(x) %3D max(0%2Cx)" alt="f(x) = max(0,x)" loading="lazy"> 反向传播，求导之后得到 <img src="https://math.jianshu.com/math?formula=f&#39;(x)%3D \\begin{cases} 1 \\quad x &gt; 0 \\\\ 0\\quad otherwise \\end{cases}" alt="f&#39;(x)= egin{cases} 1 uad x &gt; 0  0uad otherwise nd{cases}" loading="lazy"><br> 根据公式就能写出来</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># ReLU</span>
<span class="token keyword">class</span> <span class="token class-name">ReLU</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>input_tensor <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>input_tensor <span class="token operator">=</span> <span class="token builtin">input</span>
        <span class="token builtin">input</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span><span class="token builtin">input</span> <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">return</span> <span class="token builtin">input</span>

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> error<span class="token punctuation">)</span><span class="token punctuation">:</span>
        error<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_tensor <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">return</span> error
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_2-softmax以及cross-entropy-loss" tabindex="-1"><a class="header-anchor" href="#_2-softmax以及cross-entropy-loss" aria-hidden="true">#</a> 2. Softmax以及cross entropy loss</h1>`,4),b=n("p",{cases:""},[s("softmax 函数是最后一层输出的激活函数"),n("img",{src:"https://math.jianshu.com/math?formula=\\hat{y_{k}} %3D \\frac{exp(x_{k})}{\\sum_{j%3D1}^{K}exp(x_{j})}",alt:"at{y_{k}} = rac{exp(x_{k})}{um_{j=1}^{K}exp(x_{j})}",loading:"lazy"}),n("br"),s(" softmax的结果取-log得到cross entropy loss"),n("img",{src:"https://math.jianshu.com/math?formula=loss %3D \\sum_{b} -log(\\hat{y_{k}}) \\quad where y_{k} %3D 1",alt:"loss = um_{b} -log(at{y_{k}}) uad where y_{k} = 1",loading:"lazy"}),n("br"),s(" 反向求梯度的时候，因为这是反向的开头，所有直接算预测结果与正确标签的差"),n("br"),n("img",{src:"https://math.jianshu.com/math?formula=e(k) %3D \\begin{cases} y_{k}-1 \\quad y_{k}%3D1 \\\\ y_{k}(-0)\\quad otherwise \\end{cases}",alt:"e(k) = egin{cases} y_{k}-1 uad y_{k}=1  y_{k}(-0)uad otherwise nd{cases}",loading:"lazy"})],-1),_=p(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Softmax</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>input_tensor <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>label_tensor <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        input_tensor <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        <span class="token builtin">sum</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>input_tensor<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        label <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>input_tensor<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span><span class="token builtin">sum</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        <span class="token keyword">return</span> label

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> labels<span class="token punctuation">,</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>label_tensor <span class="token operator">=</span> preds
        loss <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label_tensor<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>labels <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> loss

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>label_tensor<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>label <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">1</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>label_tensor

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_3-其他loss" tabindex="-1"><a class="header-anchor" href="#_3-其他loss" aria-hidden="true">#</a> 3. 其他Loss</h1><p>这里暂时实现了比较简单的MSE. <img src="https://math.jianshu.com/math?formula=E %3D \\frac{1}{n} \\sum_{i%3D1}^n (\\hat{y}_i - y_i) ^2" alt="E = rac{1}{n} um_{i=1}^n (at{y}_i - y_i) ^2" loading="lazy"><br> 在反向传播时，对损失求梯度，根据公式求导： <img src="https://math.jianshu.com/math?formula=\\frac{\\partial E}{\\partial y}%3D\\frac{2}{n}(\\hat{y}_i-y_i)" alt="rac{artial E}{artial y}=rac{2}{n}(at{y}_i-y_i)" loading="lazy"></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MSE</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>pred <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>labels <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token comment"># loss function and its derivative</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>pred <span class="token operator">=</span> pred
        self<span class="token punctuation">.</span>labels <span class="token operator">=</span> labels
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>labels <span class="token operator">-</span> pred<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> output_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># to one-hot label</span>
        label <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>output_tensor<span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>

        error_tensor <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>output_tensor <span class="token operator">-</span> label<span class="token punctuation">)</span> <span class="token operator">/</span> output_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> error_tensor
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_4-convolution-layer" tabindex="-1"><a class="header-anchor" href="#_4-convolution-layer" aria-hidden="true">#</a> 4. Convolution Layer</h1>`,5),h={href:"https://links.jianshu.com/go?to=https%3A%2F%2Fdocs.scipy.org%2Fdoc%2Fscipy%2Freference%2Fgenerated%2Fscipy.signal.correlate.html",target:"_blank",rel:"noopener noreferrer"},f=n("br",null,null,-1),g={href:"https://links.jianshu.com/go?to=https%3A%2F%2Fpytorch.org%2Fdocs%2Fstable%2Fgenerated%2Ftorch.nn.Conv2d.html%3Fhighlight%3Dconv%23torch.nn.Conv2d",target:"_blank",rel:"noopener noreferrer"},y=n("img",{src:"https://math.jianshu.com/math?formula=(B%2C C%2CH%2CW)",alt:"(B, C,H,W)",loading:"lazy"},null,-1),w=n("img",{src:"https://math.jianshu.com/math?formula=(B%2CK%2CH^*%2CW^*)",alt:"(B,K,H*,W*)",loading:"lazy"},null,-1),x=n("br",null,null,-1),z=n("img",{src:"https://math.jianshu.com/math?formula=out(b_i%2Ck_j) %3D bias(k_j) %2B \\sum_{c%3D0}^{C-1} weight(k_j%2C c) \\star input(b_i%2C c)",alt:"out(b_i,k_j) = bias(k_j) + um_{c=0}^{C-1} weight(k_j, c) tar input(b_i, c)",loading:"lazy"},null,-1),j=n("br",null,null,-1),C=n("img",{src:"https://math.jianshu.com/math?formula=\\star",alt:"tar",loading:"lazy"},null,-1),D=n("br",null,null,-1),E=n("br",null,null,-1),F=n("br",null,null,-1),N=n("br",null,null,-1),T=n("img",{src:"https://math.jianshu.com/math?formula=x^* %3D (x-k%2B2p)%2Fs%2B1",alt:"x^* = (x-k+2p)/s+1",loading:"lazy"},null,-1),W=p(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Conv</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> stride_shape<span class="token punctuation">,</span> conv_shape<span class="token punctuation">,</span> num_kernels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># b = batch, c = channel, y, x = spatial dimension</span>
        <span class="token comment"># n = number of kernel, f = kernel shape</span>
        self<span class="token punctuation">.</span>stride_shape <span class="token operator">=</span> stride_shape
        self<span class="token punctuation">.</span>convolution_shape <span class="token operator">=</span> conv_shape
        self<span class="token punctuation">.</span>num_kernels <span class="token operator">=</span> num_kernels

        <span class="token comment"># initializte weights and bias</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random_sample<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>num_kernels<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_kernels<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>optimizer_weights <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>optimizer_bias <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>input_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>input_pad <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>gradient_weight <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>num_kernels<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gradient_bias <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># returns the input tensor for the next layer</span>
        self<span class="token punctuation">.</span>input_shape <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>shape  <span class="token comment"># (b, c, y, x)</span>
        <span class="token comment"># zero-padding, p = (f-1)/2</span>
        padding_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token comment"># padding residual</span>
        padding_r <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

        self<span class="token punctuation">.</span>input_pad <span class="token operator">=</span> np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>padding_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> padding_r<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                <span class="token punctuation">(</span>padding_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> padding_r<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;constant&#39;</span><span class="token punctuation">,</span>
                                constant_values<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment">#(b, c, y+f-1, x+f-1)</span>
        output_tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">[</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_kernels<span class="token punctuation">]</span><span class="token punctuation">,</span> input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#(b, n, y, x)</span>

        <span class="token comment"># convolution</span>
        <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> n <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_kernels<span class="token punctuation">)</span><span class="token punctuation">:</span>
              
                <span class="token comment"># for each batch, covolve input with every kernel, (c, y+f-1, x+f-1) * (f, f, f) = (1, y, x)</span>
                output_tensor<span class="token punctuation">[</span>b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal<span class="token punctuation">.</span>correlate2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_pad<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">[</span>n<span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                                   mode<span class="token operator">=</span><span class="token string">&#39;valid&#39;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># shape</span>
                <span class="token comment"># add bias on spatial dimension</span>
                bias <span class="token operator">=</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>output_tensor<span class="token punctuation">[</span>b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                output_tensor<span class="token punctuation">[</span>b<span class="token punctuation">,</span> n<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+=</span> bias

        <span class="token comment"># stride</span>
        output_tensor <span class="token operator">=</span> output_tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>stride_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token number">0</span><span class="token punctuation">:</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>stride_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

        <span class="token keyword">return</span> output_tensor
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>反向传播需要计算三个梯度, <img src="https://math.jianshu.com/math?formula=Y%3DW^TX%2Bb%2C E_n" alt="Y=W^TX+b, E_n" loading="lazy">是反向输入卷积层的error tensor :</p><ul><li><img src="https://math.jianshu.com/math?formula=E_{n-1}%3D\\frac{\\partial E}{\\partial X} %3D \\frac{\\partial E}{\\partial Y} * \\frac{\\partial Y}{\\partial X} %3D W^TE_n" alt="E_{n-1}=rac{artial E}{artial X} = rac{artial E}{artial Y} * rac{artial Y}{artial X} = W^TE_n" loading="lazy">，将梯度向上一层传递</li><li><img src="https://math.jianshu.com/math?formula=\\frac{\\partial E}{\\partial W} %3D E_nX^T" alt="rac{artial E}{artial W} = E_nX^T" loading="lazy">，用来更新weight</li><li><img src="https://math.jianshu.com/math?formula=\\frac{\\partial E}{\\partial b}%3Dsum(E_n)" alt="rac{artial E}{artial b}=sum(E_n)" loading="lazy">，用来更新bias</li></ul><h5 id="对上一层的梯度" tabindex="-1"><a class="header-anchor" href="#对上一层的梯度" aria-hidden="true">#</a> 对上一层的梯度</h5><p>在反向传播的时候，卷积层反向函数得到的输入error_tensor的尺寸为<img src="https://math.jianshu.com/math?formula=(B%2CK%2CH%2CW)" alt="(B,K,H,W)" loading="lazy">, 首先要做的是把正向的时候采样过的值按照原位置放回去.<br> 计算梯度向上传递的也是一个卷积运算，不过卷积核需要翻转过来，也就是说在前向的时候，卷积是从上到下从左到右进行的，反向的时候就需要将权值矩阵从右到左从下到上。</p><p>更加简单的操作是，在前向的时候使用cross correlation，在反向使用convolution，矩阵翻转的操作就包含在了其中。</p><p>**互相关（cross correlation）**操作：<br><img src="https://math.jianshu.com/math?formula=(f \\star g)(x) %3D \\int_{-\\infty}^{\\infty} f(\\tau)g(x%2B\\tau) d\\tau" alt="(f tar g)(x) = nt_{-nfty}^{nfty} f(au)g(x+au) dau" loading="lazy"><br> **卷积（convolution）**操作：<br><img src="https://math.jianshu.com/math?formula=(f * g)(x) %3D \\int_{-\\infty}^{\\infty} f(\\tau)g(x-\\tau) d\\tau" alt="(f * g)(x) = nt_{-nfty}^{nfty} f(au)g(x-au) dau" loading="lazy"><br> 可以看到中间那个符号的差异，就相当于是左右翻转了一次矩阵，写代码的时候还需要将卷积核矩阵上下翻转一次。</p><p>反向函数的输出尺寸应该与前向时的输入尺寸相同，也就是<img src="https://math.jianshu.com/math?formula=(B%2CC%2CH%2CW)" alt="(B,C,H,W)" loading="lazy">， 输出等于输入与卷积核的卷积，所以反向传播时的卷积核的尺寸应该是<img src="https://math.jianshu.com/math?formula=(C%2CK%2CH%2CW)" alt="(C,K,H,W)" loading="lazy"></p><p>如何得到这样的卷积核呢？可以仔细想一下前向的时候，卷积具体实现的过程。假设现在有一个（1，3，64，64）的输入特征图，与4个大小为3的卷积核做卷积（尺寸（4，3，3，3），stride=1），得到了一个（1，4，64，64）的输出特征。想象一个4层的立方体，每一层都是一个卷积核与输入卷积的结果。<br> 在反向的时候，反向的error tensor和前向的输出特征图大小一样，都是（1，4，64，64）. 这个4层立方体的第一层，是前向时第一个卷积核来的，第二层是第二个卷积核来的，依此类推。所以我们将每一个卷积核的第一层取下来叠在一起，形成一个新的卷积核（1，4，3，3），与error tensor做卷积，得到了新的error tensor的第一层（1，1，64，64）.接下来将每一个卷积核的第二层和第三层卷积也拆下来，分别叠在一起形成两个新的卷积核，得到了第二第三层，于是我们就得到了与前向时输入特征大小相同的error矩阵（1，3，64，64）.接下来就是把这个error 矩阵继续向前传播求导。</p><h5 id="对weight的梯度" tabindex="-1"><a class="header-anchor" href="#对weight的梯度" aria-hidden="true">#</a> 对weight的梯度</h5><p><img src="https://math.jianshu.com/math?formula=\\frac{\\partial E}{\\partial W} %3D E_nX^T" alt="rac{artial E}{artial W} = E_nX^T" loading="lazy">，这里需要用correlation算（不知道为啥）。得到的尺寸是<img src="https://math.jianshu.com/math?formula=(K%2CC%2Ckernel_size%2Ckernel_size)" alt="(K,C,kernel_size,kernel_size)" loading="lazy">。</p><h5 id="对bias的梯度" tabindex="-1"><a class="header-anchor" href="#对bias的梯度" aria-hidden="true">#</a> 对bias的梯度</h5><p>求和就行了。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> error_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># updates the parameters using the optimizer and returns the error tensor for the next layer</span>
        <span class="token comment"># gradient with respect to layers</span>
        <span class="token comment"># resize kernels</span>
        num_kernels_b <span class="token operator">=</span> self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        kernels_b <span class="token operator">=</span> np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>num_kernels_b<span class="token punctuation">,</span> error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># restride</span>
        error_restride <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        error_restride<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>stride_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>stride_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> error_tensor
        output <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_kernels_b<span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        padding_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment">#(b,c,y,x)</span>
        padding_r <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        error_pad <span class="token operator">=</span> np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>error_restride<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>padding_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> padding_r<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                            <span class="token punctuation">(</span>padding_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> padding_r<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;constant&#39;</span><span class="token punctuation">,</span>
                           constant_values<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_kernels_b<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                j_r <span class="token operator">=</span> error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> j <span class="token operator">-</span> <span class="token number">1</span>
                kernels_b<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">[</span>j_r<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_kernels_b<span class="token punctuation">)</span><span class="token punctuation">:</span>
                output<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal<span class="token punctuation">.</span>convolve<span class="token punctuation">(</span>error_pad<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernels_b<span class="token punctuation">[</span>j<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                           mode<span class="token operator">=</span><span class="token string">&#39;valid&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># shape</span>

        <span class="token comment"># gradient with respect to weight</span>
        self<span class="token punctuation">.</span>gradient_weight <span class="token operator">=</span> np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>num_kernels<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>convolution_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># for b in range(self.input_shape[0]):</span>
        <span class="token keyword">for</span> n <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_kernels<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>gradient_weight<span class="token punctuation">[</span>n<span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal<span class="token punctuation">.</span>correlate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_pad<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                                          error_restride<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&#39;valid&#39;</span><span class="token punctuation">)</span>

        <span class="token comment"># gradient with respect to bias</span>
        self<span class="token punctuation">.</span>gradient_bias <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>error_tensor<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>weights <span class="token operator">-=</span> <span class="token number">0.01</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>gradient_weight
        self<span class="token punctuation">.</span>bias <span class="token operator">-=</span> <span class="token number">0.01</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>gradient_bias
       
        <span class="token keyword">return</span> output

    <span class="token keyword">def</span> <span class="token function">get_gradient_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># return the gradient with respect to the weights</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>gradient_weight

    <span class="token keyword">def</span> <span class="token function">get_gradient_bias</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># return the gradient with respect to the bias</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>gradient_bias
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_5-pooling" tabindex="-1"><a class="header-anchor" href="#_5-pooling" aria-hidden="true">#</a> 5. Pooling</h1><p>池化层的思想是减少参数的数量，减少计算成本，避免过拟合。这里实现的是maxpooling， 在输入矩阵上划出一小块区域，取其中的最大值，放到输出矩阵的对应位置。要注意的是需要把找的最大值的位置记下来，因为计算反向传播的时候只有最大值的位置贡献了损失值，其他地方都是零。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Pooling</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> stride_shape<span class="token punctuation">,</span> pooling_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride_shape
        self<span class="token punctuation">.</span>pooling_shape <span class="token operator">=</span> pooling_shape
        self<span class="token punctuation">.</span>max_index <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>input_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>output_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># return input_tensor for next layer</span>

        self<span class="token punctuation">.</span>input_shape <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>shape
        self<span class="token punctuation">.</span>output_shape <span class="token operator">=</span> <span class="token punctuation">(</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                             <span class="token punctuation">(</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                             <span class="token punctuation">(</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>

        output <span class="token operator">=</span> np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_index <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                        pooling_x <span class="token operator">=</span> i <span class="token operator">*</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                        pooling_y <span class="token operator">=</span> j <span class="token operator">*</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                        pooling_field <span class="token operator">=</span> input_tensor<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> pooling_x<span class="token punctuation">:</span>pooling_x <span class="token operator">+</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                        pooling_y<span class="token punctuation">:</span>pooling_y <span class="token operator">+</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                        output<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>pooling_field<span class="token punctuation">)</span>
                        self<span class="token punctuation">.</span>max_index<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pooling_field<span class="token punctuation">)</span>

        <span class="token keyword">return</span> output

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> error_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># return error_tensor for next layer</span>

        error_extend <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">)</span>

        <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                        back_x <span class="token operator">=</span> i <span class="token operator">*</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                        back_y <span class="token operator">=</span> j <span class="token operator">*</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                        pooling_field <span class="token operator">=</span> error_extend<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> back_x<span class="token punctuation">:</span>back_x <span class="token operator">+</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                        back_y<span class="token punctuation">:</span>back_y <span class="token operator">+</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                        index0 <span class="token operator">=</span> self<span class="token punctuation">.</span>max_index<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                        index1 <span class="token operator">=</span> self<span class="token punctuation">.</span>max_index<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                        pooling_field<span class="token punctuation">[</span>index0<span class="token punctuation">,</span> index1<span class="token punctuation">]</span> <span class="token operator">+=</span> error_tensor<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> i<span class="token punctuation">,</span> j<span class="token punctuation">]</span>
                        error_extend<span class="token punctuation">[</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> back_x<span class="token punctuation">:</span>back_x <span class="token operator">+</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        back_y<span class="token punctuation">:</span>back_y <span class="token operator">+</span> self<span class="token punctuation">.</span>pooling_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> pooling_field

        <span class="token keyword">return</span> error_extend

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_6-flatten" tabindex="-1"><a class="header-anchor" href="#_6-flatten" aria-hidden="true">#</a> 6. Flatten</h1><p>前向把多维矩阵拉成一维的，反向把一维矩阵变回去。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Flatten</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>input_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># reshape and return input_tensor</span>
        self<span class="token punctuation">.</span>input_shape <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        input_tensor <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> input_tensor

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>error_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># reshape and return error_tensor</span>
        error_tensor <span class="token operator">=</span> error_tensor<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>error_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">)</span>
        <span class="token keyword">return</span> error_tensor

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_7-fully-connected" tabindex="-1"><a class="header-anchor" href="#_7-fully-connected" aria-hidden="true">#</a> 7. Fully Connected</h1><p>全连接层是输入矩阵与权重W相乘，再加上偏差bias,<img src="https://math.jianshu.com/math?formula=Y %3D W^TX" alt="Y = W^TX" loading="lazy">。在这里bias的计算是在输入X的下面在加一行1，相当于多加了一个值为1的输入神经元（参考perceptron的结构）。<br> 反向传播需要计算对于上一层的梯度以及对于权值的梯度：<br><img src="https://math.jianshu.com/math?formula=\\frac{\\partial E}{\\partial X} %3D \\frac{\\partial E}{\\partial Y}\\frac{\\partial Y}{\\partial X} %3D W^T E_n" alt="rac{artial E}{artial X} = rac{artial E}{artial Y}rac{artial Y}{artial X} = W^T E_n" loading="lazy"><br><img src="https://math.jianshu.com/math?formula=\\frac{\\partial E}{\\partial W} %3D \\frac{\\partial E}{\\partial Y}\\frac{\\partial Y}{\\partial W} %3D E_nX^T" alt="rac{artial E}{artial W} = rac{artial E}{artial Y}rac{artial Y}{artial W} = E_nX^T" loading="lazy"></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">FullyConnected</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size
        self<span class="token punctuation">.</span>delta <span class="token operator">=</span> <span class="token number">0.01</span>
        self<span class="token punctuation">.</span>input_tensor <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>output_tensor <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span>
        self<span class="token punctuation">.</span>error <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># returns the input tensor for the next layer</span>
        <span class="token comment"># extend input matrix with bias</span>
        self<span class="token punctuation">.</span>input_tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span>input_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        input_tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_tensor<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span>  
        <span class="token keyword">return</span> input_tensor

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>error_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># updates the parameters and returns the error tensor for the next layer</span>
        self<span class="token punctuation">.</span>error <span class="token operator">=</span> error_tensor
        error_tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>error<span class="token punctuation">,</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        gradient_w <span class="token operator">=</span> self<span class="token punctuation">.</span>get_gradient_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">-=</span> self<span class="token punctuation">.</span>delta <span class="token operator">*</span> gradient_w
        error_tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>error_tensor<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> error_tensor

    <span class="token keyword">def</span> <span class="token function">get_gradient_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># returns the gradient with respect to the weights, after they have been calculated in the backward-pass.</span>
        gradient_w <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_tensor<span class="token punctuation">.</span>T<span class="token punctuation">,</span> self<span class="token punctuation">.</span>error<span class="token punctuation">)</span>
        <span class="token keyword">return</span> gradient_w
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_8-data-loader" tabindex="-1"><a class="header-anchor" href="#_8-data-loader" aria-hidden="true">#</a> 8. Data Loader</h1><p>利用python的generator，来实现将数据集分为batches，并输入网络的操作。<br> 首先需要实现一个自定义的数据集类，用来读取和预处理数据。这里实现的处理有resize和归一化处理。__ <strong>len</strong> __函数返回的是数据集的长度， __ <strong>getitem</strong> __函数每次可以得到一张处理过的图片和对应的标签。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Dataset</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root_dir<span class="token punctuation">,</span> train<span class="token punctuation">,</span> test<span class="token punctuation">,</span> transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Args:
            root_dir (string): Directory with all the images.
            train (bool): if True, apply datset in training procedure
            test (bool): if True, apply datset in test procedure
            transform (bool, optional): Optional transform to be applied
        &quot;&quot;&quot;</span>
        <span class="token comment"># TODO: rewrite dataloader</span>
        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir
        self<span class="token punctuation">.</span>train <span class="token operator">=</span> train
        self<span class="token punctuation">.</span>test <span class="token operator">=</span> test
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span><span class="token builtin">dir</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token number">0</span>
        img_name <span class="token operator">=</span> self<span class="token punctuation">.</span>root_dir <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&#39;.jpg&#39;</span>
        label <span class="token operator">=</span> index
        image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_name<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>
            image <span class="token operator">=</span> image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            image <span class="token operator">=</span> self<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        <span class="token keyword">return</span> image<span class="token punctuation">,</span> label

    <span class="token keyword">def</span> <span class="token function">normalize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> arr<span class="token punctuation">)</span><span class="token punctuation">:</span>
        arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">&#39;float&#39;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            arr<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">/=</span> <span class="token number">255.0</span>
        <span class="token keyword">return</span> arr
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>接下来是实现将数据分为一个个batch送入网络的类：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">DataGenerator</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> shuffle<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        generate batch-wise data
        :param batch_size: int, number of images in a batch
        :param dataset: class Dateset
        :param shuffle: bool, if True, shuffle the sequence of data
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
        self<span class="token punctuation">.</span>dataset <span class="token operator">=</span> dataset
        self<span class="token punctuation">.</span>shuffle <span class="token operator">=</span> shuffle
    <span class="token keyword">def</span> <span class="token function">batch_generator</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token number">0</span>
        sequence <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>shuffle <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>sequence<span class="token punctuation">)</span>
        <span class="token keyword">while</span> start<span class="token operator">+</span> self<span class="token punctuation">.</span>batch_size <span class="token operator">&lt;</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
            images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
                img<span class="token punctuation">,</span> lab <span class="token operator">=</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">[</span>sequence<span class="token punctuation">[</span>i<span class="token operator">+</span>start<span class="token punctuation">]</span><span class="token punctuation">]</span>
                images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>lab<span class="token punctuation">)</span>
            start <span class="token operator">+=</span> self<span class="token punctuation">.</span>batch_size
            images <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            labels <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> images<span class="token punctuation">,</span>labels

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">next</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="_9-neural-network" tabindex="-1"><a class="header-anchor" href="#_9-neural-network" aria-hidden="true">#</a> 9. Neural Network</h1><p>按照之前写的结构的顺序，将每层依次加入神经网络。在前向传播过程中，依次执行每一层的前向函数，并传递给下一层，最后的输出与真实标签进行比较，利用loss函数计算出损失值，再以相反的顺序指向每一层的反向传播函数，迭代每一层的参数。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">NeuralNetwork</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> categories<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
        self<span class="token punctuation">.</span>categories <span class="token operator">=</span> categories

        self<span class="token punctuation">.</span>input_tensor <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>label_tensor <span class="token operator">=</span> <span class="token boolean">None</span>

        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>loss_layer <span class="token operator">=</span> <span class="token boolean">None</span>
     
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            inputs <span class="token operator">=</span> layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

        outputs<span class="token punctuation">,</span> loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        preds <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> preds

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> output_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        error_tensor <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>output_tensor<span class="token punctuation">)</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            error_tensor <span class="token operator">=</span> layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>error_tensor<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>iteration<span class="token punctuation">,</span> data_generator<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>iteration<span class="token punctuation">)</span><span class="token punctuation">:</span>
            batch_loss <span class="token operator">=</span> <span class="token number">0.0</span>
            batch_acc <span class="token operator">=</span> <span class="token number">0.0</span>
            <span class="token keyword">for</span> inputs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> data_generator<span class="token punctuation">.</span>batch_generator<span class="token punctuation">(</span><span class="token punctuation">)</span>
                onehot_labels <span class="token operator">=</span> one_hot_label<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
                outputs<span class="token punctuation">,</span>loss<span class="token punctuation">,</span> preds <span class="token operator">=</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> onehot_labels<span class="token punctuation">)</span>
                accuracy <span class="token operator">=</span> preds<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>preds<span class="token operator">==</span>labels<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                batch_loss <span class="token operator">+=</span> loss
                batch_acc <span class="token operator">+=</span> accuracy
                self<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>

            batch_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_generator<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
            batch_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_generator<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>batch_loss<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Epoch:{}: loss: {:.4f} acc:{:.4f}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>batch_loss<span class="token punctuation">,</span>batch_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataloaders<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        batch_acc <span class="token operator">=</span> <span class="token number">0</span>
     
        <span class="token keyword">for</span> inputs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> dataloaders<span class="token punctuation">.</span>batch_generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   
            onehot_labels <span class="token operator">=</span> one_hot_label<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
            outputs<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> preds <span class="token operator">=</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> onehot_labels<span class="token punctuation">)</span>
            accuracy <span class="token operator">=</span> preds<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>preds <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            batch_loss <span class="token operator">+=</span> loss
            batch_acc <span class="token operator">+=</span> accuracy
            self<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>

        batch_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloaders<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
        batch_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloaders<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
        <span class="token keyword">return</span> batch_acc

<span class="token keyword">def</span> <span class="token function">calculate_accuracy</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    idx_max <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    correct <span class="token operator">=</span> idx_max<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>idx_max<span class="token operator">==</span>labels<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> correct<span class="token operator">/</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">one_hot_label</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    onehot <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>onehot<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        onehot<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> onehot
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>最后把所有实现的模块组合在一起。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> Layers <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> Data <span class="token keyword">import</span> DataLoaders
<span class="token keyword">from</span> Loss <span class="token keyword">import</span> Loss
<span class="token keyword">from</span> Activations <span class="token keyword">import</span> Func
<span class="token keyword">import</span> copy


<span class="token keyword">if</span> __name__<span class="token operator">==</span><span class="token string">&#39;__main__&#39;</span><span class="token punctuation">:</span>
    batch_size <span class="token operator">=</span> <span class="token number">10</span>
    categories <span class="token operator">=</span> <span class="token number">2</span>
    input_size <span class="token operator">=</span> <span class="token number">64</span>
    iteration <span class="token operator">=</span> <span class="token number">30</span>
    learning_rate <span class="token operator">=</span> <span class="token number">0.01</span>


    dataset <span class="token operator">=</span> DataLoaders<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>
        root_dir<span class="token operator">=</span><span class="token string">r&#39;D:\\...\\train&#39;</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        test<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    net <span class="token operator">=</span> NeuralNetwork<span class="token punctuation">(</span>categories<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>

    net<span class="token punctuation">.</span>loss_layer <span class="token operator">=</span> Softmax<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span> 
    conv1 <span class="token operator">=</span> Conv<span class="token punctuation">.</span>Conv<span class="token punctuation">(</span>stride_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> conv_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>num_kernels<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
    pool <span class="token operator">=</span> Pooling<span class="token punctuation">.</span>Pooling<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  
    fc1_input_size <span class="token operator">=</span> <span class="token number">4096</span>  <span class="token comment"># np.prod(pool_out_shape)</span>
    fc1 <span class="token operator">=</span> FullyConnected<span class="token punctuation">.</span>FullyConnected<span class="token punctuation">(</span>fc1_input_size<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
    fc2 <span class="token operator">=</span> FullyConnected<span class="token punctuation">.</span>FullyConnected<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> categories<span class="token punctuation">)</span>

    net<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>conv1<span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Func<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pool<span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Flatten<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fc1<span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Func<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fc2<span class="token punctuation">)</span>

    data_generator <span class="token operator">=</span> DataLoaders<span class="token punctuation">.</span>DataGenerator<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span>iteration<span class="token punctuation">,</span> data_generator<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token string">&#39;Loss function for a Neural Net&#39;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>net<span class="token punctuation">.</span>loss<span class="token punctuation">,</span> <span class="token string">&#39;-x&#39;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    dataset_test <span class="token operator">=</span> DataLoaders<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>
        root_dir<span class="token operator">=</span><span class="token string">r&#39;D:\\...\\test&#39;</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        test<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_data <span class="token operator">=</span> DataLoaders<span class="token punctuation">.</span>DataGenerator<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> dataset_test<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> net<span class="token punctuation">.</span>test<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Test Accuracy: {:.4f}&#39;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,33);function q(L,X){const a=u("ExternalLinkIcon");return o(),c("div",null,[i,r,k,n("p",null,[s("完整代码："),n("a",d,[s("https://github.com/bigfishtwo/NeuralNetwork-python"),t(a)]),m,s(" 先从简单的开始。")]),v,b,_,n("p",null,[s("卷积层就是计算输入图像上的一个小范围内的数据和卷积核的卷积，实现很简单，调个函数卷积就行了，"),n("a",h,[s("scipy的卷积函数"),t(a)]),s("。"),f,s(" 这里是根据pytorch的"),n("a",g,[s("Conv2d"),t(a)]),s("的公式，假设输入的尺寸为"),y,s("，输出尺寸"),w,s("，输出与输入的关系："),x,z,j,s(" 其中"),C,s("表示2D的互相关操作，B是batch size， C是图片的通道数，H,W是图片的高和宽，K为卷积核的数量。"),D,s(" 为了保证卷积的输出与输入一致，需要在输入图像周围加一圈zero padding，也就是说要在输入周围加上一圈零，以保持卷积后的大小不变，如果需要padding的0是奇数个，就在左边多放一位。这个操作其实可以通过设置correlate函数的mode=‘same’来实现，不过我是先写的padding，所有就把代码留着了，对于加了padding的输入，correlate的mode=‘valid’。"),E,s(" stride相当于对于卷积得到的输出以一定的间隔采样，可以通过以一定间隔读index来实现。"),F,s(" 需要注意的是，stride之后的输出在反向计算梯度的过程中，是要还原回去的，也就是需要记下stride采样的点的坐标，在反向的时候按照这个位置把梯度放回去。"),N,s(" 经过padding为p，卷积核大小为k，stride大小为s，输入尺寸为(x,x)的特征图经过卷积得到的输出大小应该为 "),T]),W])}const Y=e(l,[["render",q],["__file","CNN.html.vue"]]);export{Y as default};
